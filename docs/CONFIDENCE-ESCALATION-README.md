# Confidence-Based Human Escalation System

## Overview

A sophisticated system for intelligently escalating conversations to human agents based on the **LLM's confidence** rather than hardcoded keywords.

## The Problem

Traditional chatbots use keyword-based escalation:
- User says "speak to a human" â†’ escalate
- User says "I need help" â†’ escalate

**Issues:**
- âŒ Misses edge cases you didn't anticipate
- âŒ Brittle - breaks with variations ("talk to someone", "need assistance")
- âŒ No context awareness - treats all queries the same
- âŒ AI might give wrong answer confidently

## The Solution

Use the LLM's **"feeling"** about its own certainty:

- âœ… LLM assesses its own confidence
- âœ… Multiple signals: self-assessment, hedging, response quality
- âœ… Domain-aware: stricter for medical/legal/financial
- âœ… Adaptive: handles novel situations automatically

## Quick Start

### 1. Install & Import

```typescript
import {
  createEscalationEngine,
  MessagePipelineWithEscalation,
} from '@meta-chat/orchestrator';
```

### 2. Enable in Pipeline

```typescript
const pipeline = new MessagePipelineWithEscalation({
  tenantId: 'your-tenant',
  channel: 'whatsapp',
  channelAdapters: registry,
  enableConfidenceEscalation: true, // â† Enable the feature
});

await pipeline.process(message);
```

That's it! Escalation now happens automatically based on confidence.

## How It Works

```
1. User Message â†’ "What medication should I take?"
                  â†“
2. Prompt Builder adds confidence instructions
                  â†“
3. LLM responds: "I cannot provide medical advice. [confidence: very_low]"
                  â†“
4. Confidence Analyzer extracts signals:
   - Self-assessment: very_low
   - Hedging detected: high
   - Domain: medical (high stakes)
                  â†“
5. Escalation Engine decides:
   - Overall confidence: 15%
   - Action: IMMEDIATE_ESCALATION
   - Send AI response: NO
   - Notify human: YES
```

## Files Created

### Core Implementation
- `packages/orchestrator/src/confidence-analyzer.ts` - Multi-signal confidence analysis
- `packages/orchestrator/src/confidence-prompt-builder.ts` - Self-assessment prompt system
- `packages/orchestrator/src/escalation-engine.ts` - Decision engine
- `packages/orchestrator/src/message-pipeline-with-escalation.ts` - Integrated pipeline

### Testing & Examples
- `packages/orchestrator/src/__tests__/confidence-escalation.test.ts` - Comprehensive tests
- `examples/confidence-escalation-demo.ts` - Interactive demo
- `docs/confidence-based-escalation-guide.md` - Complete guide

## Features

### Multi-Signal Analysis

1. **Self-Assessment** (50% weight)
   - LLM explicitly rates confidence: `[confidence: low]`
   - Supports: high, medium, low, very_low, percentage (85%)

2. **Hedging Detection** (25% weight)
   - Identifies uncertain language: "I'm not sure", "might be", "perhaps"
   - Counts confidence phrases as counterbalance

3. **Response Quality** (15% weight)
   - Length appropriateness
   - Completeness
   - Specificity vs vagueness

4. **Consistency Check** (10% weight) [optional]
   - Multi-sample agreement (disabled by default)

### Smart Escalation Actions

- **CONTINUE** - High confidence, send normally
- **SEND_WITH_DISCLAIMER** - Medium confidence, add warning
- **SUGGEST_REVIEW** - Low confidence, send + notify human
- **IMMEDIATE_ESCALATION** - Very low confidence, don't send

### Domain Awareness

Stricter thresholds for high-stakes topics:
- Medical: diagnosis, medication, health
- Legal: lawsuit, contract, legal advice
- Financial: investment, tax, money

### Configurable Thresholds

```typescript
const engine = createEscalationEngine();
engine.updateConfig({
  rules: {
    immediateEscalationThreshold: 0.3, // <30% = immediate
    suggestReviewThreshold: 0.6, // <60% = suggest review
  },
  analyzerConfig: {
    thresholds: {
      highStakes: 0.8, // 80% needed for medical/legal
      standard: 0.6, // 60% for general
    },
  },
});
```

## Usage Examples

### Basic Usage

```typescript
const engine = createEscalationEngine();
const promptBuilder = engine.getPromptBuilder();

// 1. Augment prompt
const systemPrompt = promptBuilder.augmentSystemPrompt(
  'You are a helpful assistant.'
);

// 2. Get LLM response
const response = await llm.complete({ messages: [...] });

// 3. Decide action
const decision = await engine.decide(response, {
  tenantId: 'tenant-1',
  conversationId: 'conv-1',
  userMessage: 'What should I do?',
});

// 4. Act on decision
if (decision.shouldSendResponse) {
  sendMessage(decision.modifiedResponse || response.content);
}
if (decision.shouldNotifyHuman) {
  notifyAgent(decision);
}
```

### Preset Configurations

```typescript
// Strict mode (medical, legal)
const strictEngine = createStrictEscalationEngine();

// Lenient mode (casual chat)
const lenientEngine = createLenientEscalationEngine();

// Standard mode
const engine = createEscalationEngine();
```

## Running Tests

```bash
# Run all tests
npm test

# Run confidence tests only
npm test confidence-escalation

# Run demo
npx tsx examples/confidence-escalation-demo.ts
```

## Demo Output

The demo shows 8 real-world scenarios:

```
ğŸ“ Example 1: High Confidence FAQ
User: What are your business hours?
AI: Our business hours are Monday through Friday, 9 AM to 5 PM EST.

Analysis:
  Confidence Level: HIGH
  Confidence Score: 87.5%
  Escalation Action: CONTINUE
  Send AI Response: âœ…
  Notify Human: âœ… NO

  Signals:
    âœ… hedging_detection: 90.0% (weight: 0.25)
    âœ… response_quality: 85.0% (weight: 0.15)
```

## Configuration Presets

| Preset | Use Case | Immediate Threshold | Suggest Threshold |
|--------|----------|---------------------|-------------------|
| **Strict** | Medical, Legal, Financial | 0.5 (50%) | 0.75 (75%) |
| **Standard** | General Support | 0.3 (30%) | 0.6 (60%) |
| **Lenient** | Casual Chat | 0.2 (20%) | 0.4 (40%) |

## Best Practices

1. **Start Strict** - Begin with high thresholds, relax over time
2. **Monitor Metrics** - Track escalation rates and false positives
3. **Domain Rules** - Use strict mode for sensitive topics
4. **A/B Test** - Compare vs keyword-based approach
5. **Feedback Loop** - Use agent feedback to tune thresholds

## Performance

- **Latency**: +10-50ms per request (negligible)
- **Tokens**: +50-100 tokens for self-assessment instructions
- **Memory**: Minimal, no persistent state

## Migration Guide

### From Keyword-Based

**Before:**
```typescript
const keywords = ['speak to human', 'talk to agent'];
if (keywords.some(k => message.includes(k))) {
  escalate();
}
```

**After:**
```typescript
const decision = await escalationEngine.decide(response, context);
if (decision.shouldNotifyHuman) {
  escalate();
}
```

### Hybrid Approach (Recommended)

Keep both during transition:

```typescript
// Check keywords first (backward compatible)
if (containsKeyword(message)) {
  return escalate('keyword');
}

// Then check confidence
const decision = await engine.decide(response, context);
if (decision.shouldNotifyHuman) {
  return escalate('low_confidence');
}
```

## Monitoring Events

```typescript
eventManager.on(EventType.HUMAN_HANDOFF_REQUESTED, (event) => {
  const { reason, confidenceScore, confidenceLevel } = event.data;

  if (reason === 'low_confidence') {
    analytics.track('confidence_escalation', {
      score: confidenceScore,
      level: confidenceLevel,
      conversationId: event.data.conversationId,
    });
  }
});
```

## Troubleshooting

### Too Many Escalations?
- Lower thresholds: `immediateEscalationThreshold: 0.2`
- Use lenient mode: `createLenientEscalationEngine()`

### Not Escalating Enough?
- Raise thresholds: `suggestReviewThreshold: 0.75`
- Use strict mode: `createStrictEscalationEngine()`
- Add domain keywords: `highStakesDomains: ['custom']`

### LLM Not Including Tags?
- Strengthen prompt instructions
- Switch strategy: `SelfAssessmentStrategy.CHAIN_OF_THOUGHT`
- Modify system prompt directly

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ConfidenceAnalyzer   â”‚
â”‚ - Self-assessment    â”‚
â”‚ - Hedging detection  â”‚
â”‚ - Quality analysis   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EscalationEngine     â”‚
â”‚ - Rules evaluation   â”‚
â”‚ - Threshold checks   â”‚
â”‚ - Action decision    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MessagePipeline      â”‚
â”‚ - Process message    â”‚
â”‚ - Apply decision     â”‚
â”‚ - Send/escalate      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## API Reference

See full documentation: [docs/confidence-based-escalation-guide.md](./confidence-based-escalation-guide.md)

## Exports

```typescript
// Analyzer
export {
  ConfidenceAnalyzer,
  ConfidenceLevel,
  ConfidenceAnalysis,
  DEFAULT_CONFIDENCE_CONFIG,
}

// Prompt Builder
export {
  ConfidencePromptBuilder,
  SelfAssessmentStrategy,
  createExplicitMarkerPromptBuilder,
  createChainOfThoughtPromptBuilder,
}

// Engine
export {
  EscalationEngine,
  EscalationAction,
  EscalationDecision,
  createEscalationEngine,
  createStrictEscalationEngine,
  createLenientEscalationEngine,
}

// Pipeline
export {
  MessagePipelineWithEscalation,
}
```

## Future Enhancements

- [ ] Logprobs integration (if provider supports)
- [ ] Multi-sample consistency checking
- [ ] Learning from agent feedback
- [ ] Per-tenant threshold tuning
- [ ] Real-time confidence metrics dashboard

## Support

- **Documentation**: [docs/confidence-based-escalation-guide.md](./confidence-based-escalation-guide.md)
- **Tests**: `packages/orchestrator/src/__tests__/confidence-escalation.test.ts`
- **Demo**: `examples/confidence-escalation-demo.ts`
- **Issues**: Report bugs or feature requests on GitHub

---

**Built for production-grade conversational AI with intelligent human-in-the-loop** â¤ï¸
