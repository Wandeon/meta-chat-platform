# Meta Chat Platform - Project Overview

**Quick Reference Guide** | Last Updated: 2025-10-08

---

## ğŸ¯ What Are We Building?

**A production-grade, multi-tenant conversational AI platform** that lets businesses deploy intelligent chatbots across multiple messaging channels with knowledge base search capabilities.

### In Simple Terms:
Think of it as your own ChatGPT that can:
- Respond on WhatsApp, Messenger, and your website
- Search through your company documents to answer questions
- Handle multiple clients/tenants on one system
- Call custom functions (check inventory, create tickets, etc.)
- Hand off to human agents when needed

---

## ğŸ—ï¸ System Architecture (High Level)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MESSAGING CHANNELS                                     â”‚
â”‚  WhatsApp | Messenger | Web Chat Widget                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API SERVER (Express.js)                                â”‚
â”‚  â€¢ Receives messages from channels                      â”‚
â”‚  â€¢ Manages tenants, channels, documents                 â”‚
â”‚  â€¢ Exposes REST API + WebSocket                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MESSAGE ORCHESTRATOR                                   â”‚
â”‚  â€¢ Routes messages through processing pipeline          â”‚
â”‚  â€¢ Searches knowledge base (RAG)                        â”‚
â”‚  â€¢ Calls AI model (OpenAI/Anthropic/Local)            â”‚
â”‚  â€¢ Executes functions                                   â”‚
â”‚  â€¢ Sends responses back to channels                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
       â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DATABASE  â”‚ â”‚ AI MODELS  â”‚
â”‚ Postgres  â”‚ â”‚ â€¢ OpenAI   â”‚
â”‚ +pgvector â”‚ â”‚ â€¢ Claude   â”‚
â”‚           â”‚ â”‚ â€¢ Ollama   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Current Status

### âœ… What's Complete (Foundation)

| Package | Status | Description |
|---------|--------|-------------|
| **@meta-chat/shared** | âœ… DONE | Types, constants, utilities |
| **@meta-chat/database** | âœ… DONE | Prisma schema + vector search |
| **@meta-chat/events** | âœ… DONE | Event bus + webhooks |
| **Deployment Docs** | âœ… DONE | Full deployment guide |
| **System Analysis** | âœ… DONE | VPS compatibility check |

### ğŸ“¦ What Needs Building (Core Features)

| Component | Status | Priority |
|-----------|--------|----------|
| **RAG Engine** | ğŸ“¦ TODO | HIGH - Document processing & search |
| **LLM Integration** | ğŸ“¦ TODO | HIGH - Multi-provider support |
| **Channel Adapters** | ğŸ“¦ TODO | HIGH - WhatsApp, Messenger, Web |
| **Message Orchestrator** | ğŸ“¦ TODO | HIGH - Core message processing |
| **API Server** | ğŸ“¦ TODO | HIGH - REST + WebSocket |
| **Dashboard** | ğŸ“¦ TODO | MEDIUM - Management UI |
| **Docker Setup** | ğŸ“¦ TODO | MEDIUM - Production deployment |

---

## ğŸ–¥ï¸ Deployment Environment

### Target System: genai.hr VPS

**Hardware:**
- 4 CPU cores (AMD EPYC)
- 7.8GB RAM (5.4GB available)
- 370GB disk space available
- Node.js 20.19.5 âœ…
- Docker + Docker Compose âœ…

**Existing Services (Running):**
- N8N automation (app.genai.hr)
- Nextcloud file storage (files.genai.hr)
- Portainer Docker management (docker.genai.hr)
- Netdata monitoring (monitor.genai.hr)

**Our Allocation:**
- Domains: `chat.genai.hr`, `chat-admin.genai.hr`
- Ports: 3000, 3001, 5432, 6379, 5672
- Memory: ~1.5GB estimated
- Disk: ~10-50GB

**Deployment Strategy:**
- Docker Compose for all services
- Nginx reverse proxy with SSL
- Localhost-only bindings
- No conflicts with existing services âœ…

---

## ğŸ¯ Core Features

### 1. Multi-Tenancy
- Each client gets isolated environment
- Separate API keys, channels, documents
- Per-tenant configuration (tone, language, features)
- Complete data isolation

### 2. Multi-Channel Support
- **WhatsApp Business API** - Most popular messaging app
- **Facebook Messenger** - Social media integration
- **Web Chat Widget** - Embeddable on any website

### 3. RAG (Retrieval-Augmented Generation)
- Upload PDFs, DOCX, TXT, Markdown documents
- Automatic text chunking and embedding
- Hybrid search (keyword + vector similarity)
- Context-aware AI responses

### 4. AI Flexibility
- **OpenAI** (GPT-4o, GPT-4o-mini)
- **Anthropic** (Claude 3.5 Sonnet, Claude 3 Haiku)
- **Local Models** (Ollama - Llama 3, Mistral, etc.)
- Easy to switch providers per tenant

### 5. Function Calling
- AI can call custom functions
- Examples: check_inventory, create_ticket, get_weather
- Up to 5 iterations per conversation turn

### 6. Human Handoff
- Detect keywords like "speak to human"
- Change conversation status to "assigned_human"
- Notify operators via webhooks

### 7. Event System
- Real-time event bus for internal components
- Webhook delivery to external systems
- RabbitMQ support for scalability
- Audit log of all events

---

## ğŸ”‘ Configuration Options

### LLM Provider Options

**Option 1: OpenAI (Recommended for Production)**
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
```
- âœ… Best function calling support
- âœ… Fast and reliable
- âœ… Great embeddings
- âš ï¸ Costs per token

**Option 2: Anthropic (Claude)**
```env
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# Still use OpenAI for embeddings
OPENAI_API_KEY=sk-...
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
```
- âœ… Excellent reasoning
- âœ… Large context window (200K)
- âœ… Strong at following instructions
- âš ï¸ Costs per token

**Option 3: Local/Ollama (Free)**
```env
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
# Still use OpenAI for embeddings (or local embeddings)
OPENAI_API_KEY=sk-...
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
```
- âœ… No API costs
- âœ… Full privacy/control
- âœ… Ollama already on your VPS
- âš ï¸ Slower than cloud APIs
- âš ï¸ Needs GPU for best performance

**Option 4: Hybrid (Best of Both Worlds)**
- Use OpenAI/Claude for production tenants
- Use Ollama for testing/development
- Configure per tenant in database

### Multi-LLM Architecture

```typescript
// Each tenant can have different LLM config
{
  "tenantId": "tenant-1",
  "settings": {
    "llm": {
      "provider": "openai",
      "model": "gpt-4o",
      "apiKey": "sk-..."  // Encrypted in DB
    }
  }
}

// Another tenant uses Claude
{
  "tenantId": "tenant-2",
  "settings": {
    "llm": {
      "provider": "anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "apiKey": "sk-ant-..."
    }
  }
}
```

---

## ğŸ“‚ Project Structure

```
meta-chat-platform/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/              ğŸ“¦ TODO - Main API server
â”‚   â”œâ”€â”€ web-widget/       ğŸ“¦ TODO - Embeddable chat
â”‚   â””â”€â”€ dashboard/        ğŸ“¦ TODO - Management UI
â”‚
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ shared/           âœ… DONE - Types, utils, constants
â”‚   â”œâ”€â”€ database/         âœ… DONE - Prisma schema + client
â”‚   â”œâ”€â”€ events/           âœ… DONE - Event system
â”‚   â”œâ”€â”€ rag/              ğŸ“¦ TODO - Document processing + search
â”‚   â”œâ”€â”€ llm/              ğŸ“¦ TODO - Multi-provider LLM client
â”‚   â”œâ”€â”€ channels/         ğŸ“¦ TODO - WhatsApp, Messenger, Web
â”‚   â””â”€â”€ orchestrator/     ğŸ“¦ TODO - Message routing
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md   âœ… DONE - System design
â”‚   â”œâ”€â”€ DEPLOYMENT.md     âœ… DONE - Deployment guide
â”‚   â”œâ”€â”€ SYSTEM-CONSTRAINTS.md âœ… DONE - Development rules
â”‚   â”œâ”€â”€ PROJECT-OVERVIEW.md   âœ… DONE - This file
â”‚   â””â”€â”€ TODO.md           âœ… DONE - Detailed task list
â”‚
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yml ğŸ“¦ TODO - Production setup
â”‚
â”œâ”€â”€ .env.example          âœ… EXISTS - Config template
â”œâ”€â”€ package.json          âœ… EXISTS - Root package
â””â”€â”€ README.md             âœ… EXISTS - Main docs
```

---

## ğŸ“ Key Technologies

| Technology | Purpose | Why? |
|------------|---------|------|
| **TypeScript** | Language | Type safety, great tooling |
| **Node.js 20** | Runtime | Modern features, good performance |
| **Express.js** | Web framework | Simple, flexible, well-supported |
| **PostgreSQL 15** | Database | ACID, reliable, pgvector support |
| **pgvector** | Vector search | Native Postgres, no extra service |
| **Prisma** | ORM | Type-safe queries, migrations |
| **Redis** | Cache/Queue | Fast, simple, battle-tested |
| **RabbitMQ** | Message queue | Durable, scalable messaging |
| **Turbo** | Monorepo build | Fast parallel builds |
| **Docker** | Deployment | Consistent environments |

---

## ğŸš€ Development Workflow

### Phase 1: Core Infrastructure âœ… DONE
- [x] Project structure
- [x] Database schema
- [x] Event system
- [x] Deployment planning

### Phase 2: AI & RAG (CURRENT)
- [ ] Multi-LLM provider abstraction
- [ ] Document loader (PDF, DOCX, etc.)
- [ ] Text chunking strategies
- [ ] Embedding generation
- [ ] Hybrid retrieval (keyword + vector)

### Phase 3: Channels & Messaging
- [ ] WhatsApp Business webhook + API
- [ ] Messenger Platform webhook + API
- [ ] WebSocket server for web chat

### Phase 4: Orchestration
- [ ] Message routing pipeline
- [ ] Context building from history
- [ ] LLM completion with streaming
- [ ] Function calling execution
- [ ] Response formatting

### Phase 5: API & Management
- [ ] REST API for CRUD operations
- [ ] Authentication middleware
- [ ] Rate limiting
- [ ] WebSocket connections
- [ ] Dashboard UI

### Phase 6: Deployment
- [ ] Docker Compose configuration
- [ ] Nginx reverse proxy setup
- [ ] SSL certificates
- [ ] Environment configuration
- [ ] Backup automation

### Phase 7: Testing & Production
- [ ] Unit tests
- [ ] Integration tests
- [ ] Load testing
- [ ] Security audit
- [ ] Production deployment

---

## ğŸ“ˆ Success Metrics

**After Deployment:**
- âœ… API responds to health checks
- âœ… Can create tenant via API
- âœ… Can upload and index documents
- âœ… Can send/receive messages on all channels
- âœ… AI responds with context from documents
- âœ… Function calling works
- âœ… Webhooks deliver reliably
- âœ… Dashboard accessible and functional

---

## ğŸ” Security Checklist

- [ ] All services bind to localhost only
- [ ] Public access via Nginx reverse proxy only
- [ ] SSL/TLS on all public endpoints
- [ ] Strong passwords generated
- [ ] API keys encrypted in database
- [ ] Rate limiting enabled
- [ ] Input validation on all endpoints
- [ ] CORS configured properly
- [ ] No secrets in git
- [ ] Regular backups scheduled

---

## ğŸ“š Documentation Links

- **[README.md](README.md)** - Project introduction and getting started
- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** - Detailed system design
- **[DEPLOYMENT.md](docs/DEPLOYMENT.md)** - Deployment guide for genai.hr VPS
- **[SYSTEM-CONSTRAINTS.md](docs/SYSTEM-CONSTRAINTS.md)** - Development rules and limits
- **[TODO.md](docs/TODO.md)** - Detailed task checklist

---

## ğŸ¤ Getting Help

**If you need to understand:**
- **What the platform does** â†’ Read this file
- **How it works internally** â†’ Read ARCHITECTURE.md
- **How to deploy it** â†’ Read DEPLOYMENT.md
- **What you can/can't do** â†’ Read SYSTEM-CONSTRAINTS.md
- **What tasks are left** â†’ Read TODO.md

**If something breaks:**
1. Check service logs: `docker-compose logs -f [service]`
2. Check nginx: `sudo nginx -t && sudo systemctl status nginx`
3. Check resources: `free -h`, `df -h`, `docker stats`
4. Check Netdata: https://monitor.genai.hr

---

## ğŸ¯ Quick Decision Guide

**"Should I use OpenAI or Claude?"**
â†’ OpenAI for better function calling, Claude for complex reasoning

**"Should I use local models?"**
â†’ Good for testing/development, but slower for production

**"How much will this cost?"**
â†’ Depends on usage. With rate limiting: $50-500/month for OpenAI/Claude

**"Can I mix providers?"**
â†’ Yes! Each tenant can use different LLM providers

**"Will this break my N8N/Nextcloud?"**
â†’ No. Completely isolated, different ports and networks

**"How long to build the rest?"**
â†’ Estimate: 3-4 weeks full-time development

**"Can I deploy without finishing everything?"**
â†’ Yes. Can deploy infrastructure now, add features incrementally

---

## ğŸ“ Next Actions

**Right Now:**
1. âœ… Review this overview
2. âœ… Check TODO.md for detailed tasks
3. â³ Decide on LLM provider(s)
4. â³ Get API keys (OpenAI, Anthropic, or both)
5. â³ Start building RAG engine + LLM integration

**This Week:**
- Build multi-LLM provider abstraction
- Implement document processing
- Set up vector search
- Test RAG retrieval

**This Month:**
- Complete all core packages
- Build API server
- Deploy to VPS
- Test end-to-end

---

**Remember:** You have a solid foundation. The database, event system, and deployment plan are done. Now it's about building the AI/messaging features on top of this foundation.

---

**Status:** ğŸŸ¡ In Progress (30% Complete)
**Next Milestone:** RAG Engine + Multi-LLM Support
